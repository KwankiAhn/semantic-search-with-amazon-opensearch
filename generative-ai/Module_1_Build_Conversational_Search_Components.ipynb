{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aede8483",
   "metadata": {},
   "source": [
    "# Build the Conversational Search Building Blocks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e93f41d1",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"Module_1_Build_Conversational_Search/module1/all_components.png\", width=\"800\"/>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c21bd0b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### In this lab, We will build the above components one by one to design an end to end conversational search application where you can simply upload a pdf and ask questions over the pdf content. The components include,\n",
    "\n",
    "* **OpenSearch** as the Vector Database\n",
    "* **Sagemaker endpoints** to host Embedding and the large language models\n",
    "* **DynamoDB** as the memory store\n",
    "* **Lambda functions** as the Document and Query Enoders\n",
    "* **Ec2 instance** to host the web application\n",
    "\n",
    "---\n",
    "\n",
    "The lab includes the following steps:\n",
    "\n",
    "1. [Get the Cloudformation outputs](#Get-the-Cloudformation-outputs)\n",
    "2. [Component 1 : OpenSearch Vector DB](#Component-1-:-OpenSearch-Vector-DB)\n",
    "3. [Component 2 : Embedding and LLM Endpoints](#Component-2-:--Embedding-and-LLM-Endpoints)\n",
    "4. [Component 3 : Memory Store](#Component-3-:--Memory-Store)\n",
    "5. [Component 4 : Document and Query Encoder](#Component-4-:--Document-and-Query-Encoder)\n",
    "6. [Component 5 : Client WebServer](#Component-5-:-Client-WebServer)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c01dbffe",
   "metadata": {},
   "source": [
    "## Get the Cloudformation outputs\n",
    "\n",
    "Here, we retrieve the services that are already deployed as a part of the cloudformation template to reduce the deployemnt time for the purpose of this lab. These services include OpenSearch cluster and the Sagemaker endpoints for the LLM and the embedding models.\n",
    "\n",
    "We also create a **env_variables** dictionary to store the parameters needed to passed onto Lambda functions (Encoders) as environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e34e89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker, boto3, json, time\n",
    "from sagemaker.session import Session\n",
    "import subprocess\n",
    "from IPython.utils import io\n",
    "from Module_1_Build_Conversational_Search import lambda_URL, lambda_exec_role as createRole, lambda_function as createLambda\n",
    "\n",
    "cfn = boto3.client('cloudformation')\n",
    "response = cfn.list_stacks(StackStatusFilter=['CREATE_COMPLETE'])\n",
    "for cfns in response['StackSummaries']:\n",
    "    if('semantic-search' in cfns['StackName']):\n",
    "        stackname = cfns['StackName']\n",
    "\n",
    "cfn_outputs = cfn.describe_stacks(StackName=stackname)['Stacks'][0]['Outputs']\n",
    "\n",
    "for output in cfn_outputs:\n",
    "    if('s3' in output['OutputKey'].lower()):\n",
    "        s3_bucket = output['OutputValue']\n",
    "\n",
    "aws_region = boto3.Session().region_name        \n",
    "env_variables = {\"aws_region\":aws_region}\n",
    "\n",
    "cfn_outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "316ab957",
   "metadata": {},
   "source": [
    "## Component 1 : OpenSearch Vector DB"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9c3a13e",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"Module_1_Build_Conversational_Search/module1/vectordb.png\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "806982f4",
   "metadata": {},
   "source": [
    "Here, we retrieve the Endpoint of the OpenSearch cluster from the cloudformation outputs, pass it to the env_variables dictionary and also describe the cluster to see the highlevel configuration quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59187261",
   "metadata": {},
   "outputs": [],
   "source": [
    "for output in cfn_outputs:\n",
    "    if('opensearch' in output['OutputKey'].lower()):\n",
    "        env_variables[output['OutputKey']] = output['OutputValue']\n",
    "        \n",
    "opensearch_ = boto3.client('opensearch')\n",
    "\n",
    "response = opensearch_.describe_domain(\n",
    "    DomainName=env_variables['OpenSearchDomainName']\n",
    ")\n",
    "\n",
    "print(\"OpenSearch Version: \"+response['DomainStatus']['EngineVersion']+\"\\n\")\n",
    "print(\"OpenSearch Configuration\\n------------------------\\n\")\n",
    "print(json.dumps(response['DomainStatus']['ClusterConfig'], indent=4))        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5358cdb",
   "metadata": {},
   "source": [
    "## Component 2 : Embedding and LLM Endpoints"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24f2cf0f",
   "metadata": {},
   "source": [
    "\n",
    "<div>\n",
    "<img src=\"Module_1_Build_Conversational_Search/module1/ml_models.png\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1f87311",
   "metadata": {},
   "source": [
    "Here we retrieve the endpoints of the LLM and the embedding models from the cloudformation outputs, pass it to the env_variables dictionary and also describe the endpoints to see the highlevel configuration quickly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c828c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_ = boto3.client('sagemaker')\n",
    "\n",
    "for output in cfn_outputs:\n",
    "    if('endpointname' in output['OutputKey'].lower()):\n",
    "        env_variables[output['OutputKey']] = output['OutputValue']\n",
    "        print(output['OutputKey'] + \" : \"+output['OutputValue']+\"\\n\"+\"------------------------------------------------\")\n",
    "        print(json.dumps(sagemaker_.describe_endpoint_config(EndpointConfigName = sagemaker_.describe_endpoint(\n",
    "    EndpointName=output['OutputValue']\n",
    "                            )['EndpointConfigName'])['ProductionVariants'][0],indent = 4))\n",
    "                        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b69420c4",
   "metadata": {},
   "source": [
    "## Component 3 : Memory Store\n",
    "\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a789f24",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"Module_1_Build_Conversational_Search/module1/memory.png\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83bb5e2f",
   "metadata": {},
   "source": [
    "Here we create the Dynamo DB table which is used as the memory store to store the history of conversations happening in the application. SessionId is the unique identifier of a conversation entry in the table which acts as the partition column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616b4a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamo = boto3.client('dynamodb')\n",
    "\n",
    "response = dynamo.create_table(\n",
    "    TableName='conversation-history-memory',\n",
    "    AttributeDefinitions=[\n",
    "        {'AttributeName': 'SessionId', 'AttributeType': 'S'}\n",
    "    ],\n",
    "    KeySchema=[\n",
    "        { 'AttributeName': 'SessionId', 'KeyType': 'HASH'}\n",
    "    ],\n",
    "    ProvisionedThroughput={'ReadCapacityUnits': 5,'WriteCapacityUnits': 5}\n",
    ")\n",
    "env_variables['DynamoDBTableName'] = response['TableDescription']['TableName']\n",
    "\n",
    "print(\"dynamo DB Table, '\"+response['TableDescription']['TableName']+\"' is created\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "780d8486",
   "metadata": {},
   "source": [
    "## Component 4 : Document and Query Encoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3163438a",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"Module_1_Build_Conversational_Search/module1/encoders.png\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "78aaacc9",
   "metadata": {},
   "source": [
    "Here we create the Lambda functions for the document and query encoder. These lambda funcitons are packaged with Langchian module. We perform the following steps,\n",
    "1. Package the dependant libraries (Langchain) and handler files for lambda functions as zip files and push to S3\n",
    "2. Create the IAM role with sufficient permissions that can be assumed by the lambda functions\n",
    "3. Create the Lambda functions in python3.9 by passing the already created env_variables as environment variables for the functions.\n",
    "```\n",
    "  { \n",
    "    'aws_region': 'us-west-2',\n",
    "    'OpenSearchDomainEndpoint': 'xxxx',\n",
    "    'OpenSearchDomainName': 'opensearchservi-xxxxxx',\n",
    "    'OpenSearchSecret': 'xxxx',\n",
    "    'EmbeddingEndpointName': 'opensearch-gen-ai-embedding-gpt-j-xx-xxxxx',\n",
    "    'LLMEndpointName': 'opensearch-gen-ai-llm-falcon-7b-xx-xx',\n",
    "    'DynamoDBTableName': 'conversation-history-memory'\n",
    "  }\n",
    "```\n",
    "\n",
    "4. Create external Lambda URL for queryEncoder lambda to be called from outside world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6939b677",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the ARN of the IAM role (deployed in cloud formation) for the lambda to assume.\n",
    "\n",
    "iam_ = boto3.client('iam')\n",
    "response = iam_.get_role(\n",
    "    RoleName='LambdaRoleForEncoders'\n",
    ")\n",
    "\n",
    "roleARN = response['Role']['Arn']\n",
    "\n",
    "#Create Lambda functions\n",
    "encoders = ['queryEncoder','documentEncoder']\n",
    "createLambda.createLambdaFunction(encoders,roleARN,env_variables)\n",
    "\n",
    "#Create Lambda URL\n",
    "account_id=roleARN.split(':')[4]\n",
    "query_invoke_URL = lambda_URL.createLambdaURL('queryEncoder',account_id)\n",
    "print(\"\\nLambdaURL created, URL: \"+query_invoke_URL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8fc4b86f",
   "metadata": {},
   "source": [
    "## Component 5 : Client WebServer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9170aa9",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"Module_1_Build_Conversational_Search/module1/webserver.png\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9c07a61",
   "metadata": {},
   "source": [
    "Before you go into the final step, you need to add your current **PUBLIC IP** address to the ec2 security group so that you are able to access the web application (chat interface) that you are going to host in the next step.\n",
    "\n",
    "<h3 style=\"color:red;\"><U>Warning</U></h3>\n",
    "<h4>Without doing the below steps, you will not be able to proceed further.</h4>\n",
    "\n",
    "<div>\n",
    "    <h3 style=\"color:red;\"><U>Enter your IP address </U></h3>\n",
    "    <h4> STEP 1. Get your IP address <span style=\"display:inline;color:blue\"><a href = \"https://ipinfo.io/ip \">HERE</a></span></h4>\n",
    "</div>\n",
    "\n",
    "<h4>STEP 2. Run the below cell </h4>\n",
    "<h4>STEP 3. Paste the IP address in the input box that prompts you to enter your IP</h4>\n",
    "<h4>STEP 4. Press ENTER</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc899b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ip = (input(\"Enter your IP : \")).split(\".\")\n",
    "my_ip.pop()\n",
    "IP = \".\".join(my_ip)+\".0/24\"\n",
    "\n",
    "port_protocol = {443:'HTTPS',80:'HTTP',8501:'streamlit'}\n",
    "\n",
    "IpPermissions = []\n",
    "\n",
    "for port in port_protocol.keys():\n",
    "     IpPermissions.append({\n",
    "            'FromPort': port,\n",
    "            'IpProtocol': 'tcp',\n",
    "            'IpRanges': [\n",
    "                {\n",
    "                    'CidrIp': IP,\n",
    "                    'Description': port_protocol[port]+' access',\n",
    "                },\n",
    "            ],\n",
    "            'ToPort': port,\n",
    "        })\n",
    "\n",
    "IpPermissions\n",
    "\n",
    "for output in cfn_outputs:\n",
    "    if('securitygroupid' in output['OutputKey'].lower()):\n",
    "        sg_id = output['OutputValue']\n",
    "        \n",
    "#sg_id = 'sg-0e0d72baa90696638'\n",
    "\n",
    "ec2_ = boto3.client('ec2')        \n",
    "\n",
    "response = ec2_.authorize_security_group_ingress(\n",
    "    GroupId=sg_id,\n",
    "    IpPermissions=IpPermissions,\n",
    ")\n",
    "\n",
    "print(\"\\nIngress rules added for the security group, ports:protocol - \"+json.dumps(port_protocol)+\" with my ip - \"+IP)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb338301",
   "metadata": {},
   "source": [
    "Finally, We are ready to host our conversational search application, here we perform the following steps, Steps 2-5 are achieved by executing the terminal commands in the ec2 instance using a SSM client.\n",
    "1. Update the web application code files with lambda url (in [api.py](https://github.com/aws-samples/semantic-search-with-amazon-opensearch/blob/main/generative-ai/Module_1_Build_Conversational_Search/webapp/api.py)) and s3 bucket name (in [app.py](https://github.com/aws-samples/semantic-search-with-amazon-opensearch/blob/main/generative-ai/Module_1_Build_Conversational_Search/webapp/app.py))\n",
    "2. Archieve the application files and push to the configured s3 bucket.\n",
    "3. Download the application (.zip) from s3 bucket into ec2 instance (/home/ec2-user/), and uncompress it.\n",
    "4. We install the streamlit and boto3 dependencies inside a virtual environment inside the ec2 instance.\n",
    "5. Start the streamlit application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3f35a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify the code files with lambda url and s3 bucket names\n",
    "query_invoke_URL_cmd = query_invoke_URL.replace(\"/\",\"\\/\")\n",
    "\n",
    "with io.capture_output() as captured:\n",
    "    #Update the webapp files to include the s3 bucket name and the LambdaURL\n",
    "    !sed -i 's/API_URL_TO_BE_REPLACED/{query_invoke_URL_cmd}/g' Module_1_Build_Conversational_Search/webapp/api.py\n",
    "    !sed -i 's/pdf-repo-uploads/{s3_bucket}/g' Module_1_Build_Conversational_Search/webapp/app.py\n",
    "    #Push the WebAPP code artefacts to s3\n",
    "    !cd Module_1_Build_Conversational_Search/webapp && zip -r ../webapp.zip *\n",
    "    !aws s3 cp Module_1_Build_Conversational_Search/webapp.zip s3://$s3_bucket\n",
    "        \n",
    "#Get the Ec2 instance ID which is already deployed\n",
    "response = cfn.describe_stack_resources(\n",
    "    StackName=stackname\n",
    ")\n",
    "for resource in response['StackResources']:\n",
    "    if(resource['ResourceType'] == 'AWS::EC2::Instance'):\n",
    "        ec2_instance_id = resource['PhysicalResourceId']\n",
    "   \n",
    "# function to execute commands in ec2 terminal\n",
    "def execute_commands_on_linux_instances(client, commands):\n",
    "    resp = client.send_command(\n",
    "        DocumentName=\"AWS-RunShellScript\", # One of AWS' preconfigured documents\n",
    "        Parameters={'commands': commands},\n",
    "        InstanceIds=[ec2_instance_id],\n",
    "    )\n",
    "    return resp['Command']['CommandId']\n",
    "\n",
    "ssm_client = boto3.client('ssm') \n",
    "\n",
    "commands = [\n",
    "            'aws s3 cp s3://'+s3_bucket+'/webapp.zip /home/ec2-user/',\n",
    "            'unzip -o /home/ec2-user/webapp.zip -d /home/ec2-user/'  ,  \n",
    "            'sudo chmod -R 0777 /home/ec2-user/',\n",
    "            'aws s3 cp /home/ec2-user/pdfs s3://'+s3_bucket+'/sample_pdfs/ --recursive',\n",
    "            'python3 -m venv /home/ec2-user/.myenv',\n",
    "            'source /home/ec2-user/.myenv/bin/activate',\n",
    "            'pip install streamlit',\n",
    "            'pip install boto3',\n",
    "    \n",
    "            #start the web applicaiton\n",
    "            'streamlit run /home/ec2-user/app.py',\n",
    "            ]\n",
    "\n",
    "command_id = execute_commands_on_linux_instances(ssm_client, commands)\n",
    "\n",
    "ec2_ = boto3.client('ec2')\n",
    "response = ec2_.describe_instances(\n",
    "    InstanceIds=[ec2_instance_id]\n",
    ")\n",
    "public_ip = response['Reservations'][0]['Instances'][0]['PublicIpAddress']\n",
    "print(\"Please wait while the application is being hosted . . .\")\n",
    "time.sleep(10)\n",
    "print(\"\\nApplication hosted successfully\")\n",
    "print(\"\\nClick the below URL to open the application. It may take up to a minute or two to start the application, Please keep refreshing the page if you are seeing connection error.\\n\")\n",
    "print('http://'+public_ip+\":8501\")\n",
    "print(\"\\nCheck the below video on how to interact with the application\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3609bde4",
   "metadata": {},
   "source": [
    "<h3>Play with the chat application</h3>\n",
    "<div>\n",
    "<img src=\"Module_1_Build_Conversational_Search/module1/module1.gif\"/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
